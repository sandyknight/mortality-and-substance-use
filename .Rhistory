library(rvest)
url <- "https://www.glassdoor.co.uk/Reviews/NESTA-Reviews-E37043.htm"
read_html(url)
html <- read_html(url)
html |> html_elements()
html |> html_attrs()
html |> html_text()
html |> html_elements("div")
html |> html_elements("div") |> html_attr("class")
html |> html_elements("div") |> html_attr("class") == "content"
divs <- html |> html_elements("div")
divs |> html_attr("class") == "content"
divs[divs |> html_attr("class") == "content"]
divs[divs |> html_attr("class") == "content",]
divs[(divs |> html_attr("class") == "content")]
library(tinytex)
tinytex::install_tinytex()
tinytex::is_tinytex()
reticulate::repl_python()
library(rvest)
url <- "https://www.tesco.com/groceries/en-GB/shop/drinks/spirits/all"
html <- read_html(url)
?read_html()
sesh <- session(url)
install.packages("Rcrawler")
library(Rcrawler)
?Rcrawler()
c <- ContentScraper(url)
c
pi
exp(1)
f <- function(x){
fx <-   (1 / sqrt((2*pi))) * (exp(1)^(-x^2/2))
return(fx)
}
f(1)
seq(0,1, 0.01)
f(seq(0,1, 0.01))
plot(f(seq(0,1, 0.01)))
density((f(seq(0,1, 0.01))))
plot(density((f(seq(0,1, 0.01)))))
f <- function(x){
fx <-   (1 / sqrt((2*pi))) * (exp(1)^((-x^2)/2))
return(fx)
}
plot(density((f(seq(0,1, 0.01)))))
f(seq(0,1, 0.01))
plot(f(seq(0,1, 0.01)))
rnorm(n = 100, mean = 0, sd = 1)
plot(rnorm(n = 100, mean = 0, sd = 1))
plot(f(seq(0,1, 0.01)))
density(f(seq(0,1, 0.01)))
plot(density(f(seq(0,1, 0.01))))
plot(density(rnorm(n = 100, mean = 0, sd = 1)))
plot(density(rnorm(n = 1000, mean = 0, sd = 1)))
plot(density(rnorm(n = 10000, mean = 0, sd = 1)))
plot(density(rnorm(n = 100000, mean = 0, sd = 1)))
plot(density(rnorm(n = 1000000, mean = 0, sd = 1)))
plot(density(f(seq(0,1, 0.00001))))
plot(density(rnorm(n = 1000000, mean = 0, sd = 1)))
plot(f(seq(0,1, 0.00001)))
plot(f(seq(0,1, 0.00001)))
plot(f(seq(0,1000,1)))
plot(f(seq(1,1000,1)))
density(f(seq(1,1000,1)))
plot(density(f(seq(1,1000,1))))
plot(density(f(seq(1,100000,1))))
plot(density(f(seq(1,100,1))))
rnorm(n = 1000000, mean = 0, sd = 1))
rnorm(n = 1000000, mean = 0, sd = 1)
rnorm(n = 1, mean = 0, sd = 1)
f(1)
f(-1)
reticulate::repl_python()
reticulate::repl_python()
install.packages(c("BH", "BiasedUrn", "blob", "bnlearn", "bpbounds", "broom", "BuyseTest", "Cairo", "car", "CausalGPS", "causaloptim", "CausalQueries", "causalweight", "checkmate", "chron", "cjoint", "class", "classInt", "cli", "clue", "clusterGeneration", "cna", "cobalt", "coin", "collapse", "colorspace", "colourpicker", "compositions", "config", "ctv", "cubature", "curl", "data.table", "data.tree", "datawizard", "dbarts", "dbplyr", "deldir", "DEoptimR", "designmatch", "dfoptim", "DiagrammeR", "distributional", "doRNG", "DoubleML", "dplyr", "DRDID", "dreamerr", "drtmle", "DT", "dtplyr", "DynTxRegime", "e1071", "earth", "ECOSolveR", "eefAnalytics", "EffectLiteR", "effectsize", "EnvStats", "evalITR", "expm", "fastDummies", "fixest", "flextable", "FNN", "forcats", "forecast", "Formula", "future", "future.apply", "gam", "gargle", "gdata", "gdtools", "generalCorr", "GenSA", "geometry", "gfoRmula", "ggdag", "ggfittext", "ggplot2", "ggplotify", "ggrepel", "ggsci", "glmnet", "glmx", "gmp", "gnm", "googledrive", "googlesheets4", "graphlayouts", "grf", "gridpattern", "gt", "gtable", "haven", "hettx", "Hmisc", "hms", "htmlTable", "httr2", "idem", "igraph", "influenceR", "insight", "interp", "inum", "isoband", "ivdesc", "ivmodel", "ivreg", "janitor", "keras", "kernlab", "KFAS", "ks", "labeling", "labelled", "lava", "lavaan", "lawstat", "lfe", "lhs", "libcoin", "limSolve", "lme4", "locfit", "loo", "LowRankQP", "lpSolve", "ltmle", "lubridate", "magick", "marginaleffects", "markdown", "match2C", "Matching", "MatchIt", "matchMulti", "MatchThem", "Matrix", "MatrixModels", "matrixStats", "mboost", "mclust", "meboot", "medflex", "MendelianRandomization", "metafor", "metR", "mets", "mice", "microbenchmark", "microsynth", "minqa", "miscTools", "mlbench", "mlr3", "mlr3learners", "mlr3misc", "mlr3tuning", "modelbased", "modelr", "multcomp", "mvnfast", "mvtnorm", "ncvreg", "network", "nleqslv", "nnls", "nomnoml", "np", "odbc", "officer", "optimx", "optmatch", "osqp", "packrat", "paradox", "parallelly", "parameters", "partykit", "pbapply", "pbkrtest", "pcalg", "pdftools", "performance", "plm", "plotly", "plotrix", "plyr", "polspline", "polyclip", "posterior", "pracma", "pROC", "processx", "prodlim", "progressr", "pryr", "ps", "psych", "Publish", "qpdf", "qtl", "Qtools", "quantmod", "quantreg", "qvcalc", "ranger", "rbibutils", "rcdd", "RcppArmadillo", "RcppEigen", "RcppParallel", "RcppTOML", "rdflib", "Rdpack", "rdrobust", "reactR", "readODS", "readr", "readstata13", "readxl", "redland", "rematch", "repr", "reticulate", "Rglpk", "riskRegression", "rjags", "rlemon", "Rmpfr", "rms", "robustbase", "rootSolve", "rpart", "rpsftm", "rrcov", "rsample", "rsconnect", "RSQLite", "rstan", "rstanarm", "rstantools", "rsvg", "s2", "scpi", "scs", "sf", "sfsmisc", "shinyWidgets", "showtext", "slider", "sna", "snakecase", "sp", "spatstat.data", "spatstat.geom", "spatstat.utils", "speedglm", "StanHeaders", "statmod", "statnet.common", "stringi", "stringr", "SuperLearner", "survey", "svglite", "Synth", "systemfit", "tableHTML", "tensorflow", "tesseract", "texreg", "TH.data", "tidygraph", "tidysynth", "tidyverse", "timechange", "timeDate", "timereg", "tmle", "treemap", "treemapify", "tseries", "tzdb", "ufs", "units", "uuid", "V8", "varhandle", "vcd", "VGAM", "viridis", "viridisLite", "vroom", "warp", "wCorr", "webshot", "WeightIt", "WGCNA", "wk", "writexl", "xgboost", "XML", "xts", "yulab.utils", "zoo"))
library(tidyverse)
library(updateR)
library(ical)
cal <- ical::ical_parse(file = "../Knight Sandy Calendar.ics")
cal_df <- ical::ical_parse_df(cal)
cal_df <- ical::ical_parse_df(file = "../Knight Sandy Calendar.ics")
cal_df
library(tidyverse)
as_tibble(cal_df)
df <- as_tibble(cal_df)
pull(df, summary) |> unique()
df |>
filter(str_detect(summary, "SK|Sandy"))
df |>
filter(str_detect(summary, "SK|Sandy")) |>
filter(str_detect("AL|A/L|Annual leave|annual leave|Annual Leave"))
df |>
filter(str_detect(summary, "SK|Sandy")) |>
filter(str_detect(summary, "AL|A/L|Annual leave|annual leave|Annual Leave"))
al <-
df |>
filter(str_detect(summary, "SK|Sandy")) |>
filter(str_detect(summary, "AL|A/L|Annual leave|annual leave|Annual Leave"))
al |>
select(summary, start, end)
rm(cal);rm(cal_df);rm(df)
al |>
select(summary, start, end)
al |>
select(summary, start, end) |>
filter(!str_detect(summary, "priv"))
al <-
al |>
select(summary, start, end) |>
filter(!str_detect(summary, "priv"))
al
mean(36, 60, 44, 16. 24)
mean(36, 60, 44, 16, 24)
setwd("~/mortality_and_lyl_substance_misuse")
library(testthat)
poisoning_deaths_by_age <-
process_deaths_in_treatment(
file_path = deaths_in_treatment_file, years = 2022, by_treatment_status = TRUE, exclude_poisoning = TRUE, exclude_alcohol_specific_deaths = TRUE, by = "age"
) |>
filter(treatment_status != "Died one or more years following discharge") |>
group_by(age) |>
summarise(count = sum(count))
library(testthat)
source("drug_deaths_functions.R")
source("R/drug_deaths_functions.R")
poisoning_deaths_by_age <-
process_deaths_in_treatment(
file_path = deaths_in_treatment_file, years = 2022, by_treatment_status = TRUE, exclude_poisoning = TRUE, exclude_alcohol_specific_deaths = TRUE, by = "age"
) |>
filter(treatment_status != "Died one or more years following discharge") |>
group_by(age) |>
summarise(count = sum(count))
drug_poisoning_deaths_file <-
"data/raw/ndtms_mortality_data.parquet"
deaths_in_treatment_file <-
"data/raw/tx_deaths_la_2122_2223.parquet"
poisoning_deaths_by_age <-
process_deaths_in_treatment(
file_path = deaths_in_treatment_file, years = 2022, by_treatment_status = TRUE, exclude_poisoning = TRUE, exclude_alcohol_specific_deaths = TRUE, by = "age"
) |>
filter(treatment_status != "Died one or more years following discharge") |>
group_by(age) |>
summarise(count = sum(count))
non_poisoning_deaths_by_age <-
process_poisoning_data(
file_path = drug_poisoning_deaths_file, date_of = "occurence", years = 2022, by = "age"
) |>
rename("age" = ageinyrs) |>
group_by(age) |>
summarise(count = sum(count))
deaths_by_age <-
bind_rows(
poisoning_deaths_by_age,
non_poisoning_deaths_by_age
) |>
group_by(age) |>
summarise(count = sum(count))
life_tables <- read_csv("data/processed/life_tables.csv")
life_tables<-
life_tables |>
group_by(age) |>
summarise(across(ex_male:ex_female, mean)) |>
rowwise() |>
mutate(ex_average = mean(x = c(ex_male, ex_female))) |>
select(age,ex_average)
yll <-
left_join(deaths_by_age, life_tables, by = "age")  |>
mutate(YLL = count * ex_average)
cut_age_groups <-
function(x) {
cut(
x,
breaks = c(17, 24, 34, 44, 54, 64, 74, 84, Inf),
labels = c(
"18-24",
"25-34",
"35-44",
"45-54",
"55-64",
"65-74",
"75-84",
"85+"
),
right = TRUE
)
}
yll_age_group <-
yll |>
mutate(age_group = cut_age_groups(age)) |>
group_by(age_group) |>
summarise(
count = sum(count),
YLL = sum(YLL)
)
sum(yll_age_group$count)
yll_age_group
yll_age_group |>
rename("Deaths (n)" = count) |>
rename_with(.cols = c(age_group), .fn = snakecase::to_sentence_case)
yll_age_group |>
rename("Deaths (n)" = count) |>
rename_with(.cols = c(age_group), .fn = snakecase::to_sentence_case) |>
janitor::add_totals_row()
yll_age_group |>
rename("Deaths (n)" = count) |>
rename_with(.cols = c(age_group), .fn = snakecase::to_sentence_case) |>
janitor::adorn_totals(where = "row")
yll_age_group |>
rename("Deaths (n)" = count) |>
rename_with(.cols = c(age_group), .fn = snakecase::to_sentence_case) |>
janitor::adorn_totals(where = "row") |>
write_csv("data/processed/yll_age_group.csv")
testthat::test_that("Total deaths by age group equal to total deaths in national data",{
expect_equal(
sum(yll_age_group$count),
sum(pull(filter(national_data, death_category != "Non-poisoning deaths: Died one or more years following discharge"), count))
)}
)
national_data <-
combine_national_data(
poisoning_data = process_poisoning_data(file_path = drug_poisoning_deaths_file,
date_of = "occurence",
years = 2022),
treatment_deaths_data = process_deaths_in_treatment(
file_path = deaths_in_treatment_file,
years = 2022,
exclude_poisoning = TRUE,
by_treatment_status = TRUE,
by_death_cause = FALSE,
exclude_alcohol_specific_deaths = TRUE
)
)
national_data <-
relabel_national_data(national_data = national_data)
testthat::test_that("Total deaths by age group equal to total deaths in national data",{
expect_equal(
sum(yll_age_group$count),
sum(pull(filter(national_data, death_category != "Non-poisoning deaths: Died one or more years following discharge"), count))
)}
)
yll_age_group
yll_age_group[,"count"]
yll
as.matrix(yll)
yll
calculate_yll <-
function(number.deaths,
average.age.death,
model.life.expectancy,
discount.rate = 0.03,
beta.constant = 0.04,
modulation.constant = 0,
adjustment.constant = 0.1658) {
##abbreviate inputs
N <- number.deaths
a <- average.age.death
L <- model.life.expectancy
r <- discount.rate
b <- beta.constant
K <- modulation.constant
CC <- adjustment.constant
##do calculations
if(discount.rate==0){
N*(K*CC*((exp(-b*a))/b^2)*((exp(-b*L))*(-b*(L+a)-1)-(-b*a-1))+((1-K)*L))
} else {
N*(K*((CC*exp(r*a))/(-(r+b)^2))*((exp(-(r+b)*(L+a))*(-(r+b)*(L+a)-1))-(exp(-(r+b)*a)*(-(r+b)*a-1)))+((1-K)/r)*((1-exp(-r*L))))
}
}
yll |>
rowwise() |>
mutate(YLL_ii = calculate_yll(number.deaths = count, average.age.death = age, model.life.expectancy = ex_average))
yll |>
rowwise() |>
mutate(YLL_ii = calculate_yll(number.deaths = count, average.age.death = age, model.life.expectancy = ex_average))
yll <-
yll |>
rowwise() |>
mutate(YLL_ii = calculate_yll(number.deaths = count, average.age.death = age, model.life.expectancy = ex_average))
yll |>
mutate(age_group = cut_age_groups(age)) |>
group_by(age_group) |>
summarise(
count = sum(count),
YLL = sum(YLL),
YLL_ii = sum(YLL_ii)
)
yll_age_group_ii <-
yll |>
mutate(age_group = cut_age_groups(age)) |>
group_by(age_group) |>
summarise(
count = sum(count),
YLL = sum(YLL),
YLL_ii = sum(YLL_ii)
)
yll_age_group_ii |>
ggplot(aes(x = age_group, y= YLL_ii)) +
geom_col(colour = "black", fill = afcolours::af_colours(n = 1)[1], width = 0.6) +
scale_y_continuous(labels = scales::comma) +
labs(x = "Age group", y = "YLL", title = "Years of life lost due to deaths associated with drug use", subtitle = glue::glue("The crude expected years of life lost is {scales::comma(sum(yll_age_group$YLL))}"))
yll_age_group_ii |>
ggplot(aes(x = age_group, y = YLL_ii)) +
geom_col(colour = "black",
fill = afcolours::af_colours(n = 1)[1],
width = 0.6) +
scale_y_continuous(labels = scales::comma) +
labs(
x = "Age group",
y = "YLL",
title = "Years of life lost due to deaths associated with drug use",
subtitle = glue::glue(
"The crude expected years of life lost is {scales::comma(sum(yll_age_group_ii$YLL_ii))}"
)
)
yll_age_group_ii |>
ggplot(aes(x = age_group, y = YLL_ii)) +
geom_col(colour = "black",
fill = afcolours::af_colours(n = 1)[1],
width = 0.6) +
scale_y_continuous(labels = scales::comma) +
labs(
x = "Age group",
y = "YLL",
title = "Years of life lost due to deaths associated with drug use",
subtitle = glue::glue(
"The discounted expected years of life lost is {scales::comma(sum(yll_age_group_ii$YLL_ii))}"
)
)
styler:::style_active_file()
yll_age_group_ii
yll_age_group_ii |>
pivot_longer(cols = c(YLL, YLL_ii), names_to = "method", values_to = "YLL")
yll_age_group_ii |>
pivot_longer(cols = c(YLL, YLL_ii), names_to = "method", values_to = "YLL") |>
mutate(method = case_match(method, "YLL" ~ "Method I", "YLL_ii" ~ "Method II"))
library(openxlsx)
?read.xlsx
read.xlsx(
xlsxFile = url, rows = c(1:183), cols = c(1,2,3,4,16)
)
url <-
"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/analysisofpopulationestimatestoolforuk/2023/theanalysisofpopulationestimatestool2023ew.xlsx"
read.xlsx(
xlsxFile = url, rows = c(1:183), cols = c(1,2,3,4,16)
)
read.xlsx(
xlsxFile = url, rows = c(1:183), cols = c(1,2,3,4,16), sheet = "MYEB2"
)
population_2022 <- # Get 2022 mid-year population estimate for England
read.xlsx(
xlsxFile = url, rows = c(1:183), cols = c(1,2,3,4,16), sheet = "MYEB2"
)
write_csv(population_2022, "data/processed/population_2022.csv")
population_2022 <-
read_csv("data/processed/population_2022.csv")
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022))
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022)) |>
mutate(age_group = cut_age_groups(age))
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022)) |>
rowwise() |>
mutate(age_group = cut_age_groups(age))
yll |>
mutate(age_group = cut_age_groups(age))
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022), .groups = "drop") |>
mutate(age_group = cut_age_groups(age))
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022), .groups = "drop") |>
mutate(age_group = cut_age_groups(age)) |>
filter(!is.na(age_group))
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022), .groups = "drop") |>
mutate(age_group = cut_age_groups(age)) |>
filter(!is.na(age_group)) |>
group_by(age_group) |>
summarise(population_2022 = sum(population_2022), .groups = "drop")
population_2022_age_group <-
population_2022 |>
group_by(age) |>
summarise(population_2022 = sum(population_2022), .groups = "drop") |>
mutate(age_group = cut_age_groups(age)) |>
filter(!is.na(age_group)) |>
group_by(age_group) |>
summarise(population_2022 = sum(population_2022), .groups = "drop")
sum(population_2022_age_group$population_2022)
scales::comma(sum(population_2022_age_group$population_2022))
bind_rows(
yll_age_group_ii,
population_2022_age_group
)
left_join(
yll_age_group_ii,
population_2022_age_group
)
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / population_2022)
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / population_2022) |>
mutate(YLL_per_population  = YLL_ii / population_2022)
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / (population_2022/100e03)) |>
mutate(YLL_per_population  = YLL_ii / population_2022)
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / (population_2022/100e03)) |>
mutate(YLL_ii_per_population  = YLL_ii / population_2022)
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / (population_2022/100e03)) |>
mutate(YLL_ii_per_population  = YLL_ii / (population_2022/100e03))
yll_age_group_ii <-
left_join(
yll_age_group_ii,
population_2022_age_group
) |>
mutate(YLL_per_population  = YLL / (population_2022/100e03)) |>
mutate(YLL_ii_per_population  = YLL_ii / (population_2022/100e03))
yll_age_group_ii |>
janitor::adorn_totals(where = "row")
library(arrow)
read_parquet("data/raw/ndtms_mortality_data.parquet")
